{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Interpretable Machine Learning Notes"
      ],
      "metadata": {
        "id": "-OoK5T6i6y6Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Interpretable Machine Learning is an umbrella term that captures the extraction of relevant knowledge from a Machine-Learning model concerning relationships either contained in data or learned by model*"
      ],
      "metadata": {
        "id": "eH9kBcaw8AfK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chapter 2 : Interpretability"
      ],
      "metadata": {
        "id": "4C0cButr7AYT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is interpretability?\n",
        "\n",
        "*Interpretability is degreee to which a human can understand the cause of a decision*\n",
        "\n",
        "*Interpretability is the degree to which a human can consistentlu predict the model's result.*\n",
        "\n",
        "What is algorithmic transparency?\n",
        "\n",
        "It is about how the algorithm learns a model from the data and what kind of relationships it can learn. It only requires knowledge of the algorithm and not the data or the learned model.\n",
        "\n",
        "Need for interpretability?\n",
        "\n",
        "  - Human curiosity and learning\n",
        "  - Find meaning in the world\n",
        "  - Goal of science (Extract additional knowledge captured by the model)\n",
        "  - Safety measures\n",
        "  - Detect Bias (There are constraints that are part of the problem formulation but cannot be covered in the loss function or evaluation metric)\n",
        "  - Social Acceptance\n",
        "  - Debug and Audit\n",
        "\n",
        "\n",
        "Desirable featuers of Machine-Learning model:\n",
        "  - Fairness\n",
        "  - Privacy\n",
        "  - Reliability\n",
        "  - Causality\n",
        "  - Trust\n",
        "\n",
        "  \n",
        "  Side Note - Proxy features should be avoided as the input feature can be a proxy for a causal feature but do not actually cause the outcome. (Use only causal features)\n",
        "\n",
        "  \n",
        "  **Intrisinic/Model-Specific Interpretability Method** : Refers to machine learning models that are considered interpretable due to their simple structure.\n",
        "\n",
        "  **Post-hoc/Model Agnostic Interpretability Method** : Refers to the application of interpretation methods after model training."
      ],
      "metadata": {
        "id": "fYvER_4Z8cqF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key differntiating factors between interpretability methods:\n",
        "\n",
        "  - Results of Interpretation Method Categories:\n",
        "    1.  Feature Summary Statistic - Feature Importance/Pairwise Feature Interaction Strenght\n",
        "    2.  Feature Summary Viz - Some feature statistic only meaningful when visualized (PDP)\n",
        "    3.  Model Internals(Model Specific) - Interpretation of intrinsically interpretable model (lm weights/decision tree split rule/ visualizations of feature decoders in CNNs)\n",
        "    4. Data Points - Counter factual explanations (useful in text/image data not for tabular data)\n",
        "    5. Intrinsically Interpretable Model - Interpret black-box models by approximating them with an interpretable model and then interpret the interpretable model.\n",
        "\n",
        "\n",
        "  - Model Specific v/s Model Agnostic\n",
        "\n",
        "  - Scope of Interpretability:\n",
        "\n",
        "    1. Algorithmic Transparency (Ideal case - no need for interpretabilty methods)\n",
        "    2. Global/Holistic Model Interpretability - Understanding how model makes decisions based on holistic view of its feature and each of the learned components. Hard to achieve in practice.\n",
        "    3. Global Model Interpretability on a Modular Level\n",
        "    4. Local Interpretability for a Single Prediction - More accurate than global explanations as the other complex behavior of the model might behave more pleasantly for a singe instance.\n",
        "    5. Local Interpretability for a Group of Predictions - Either global model interpretations on modular level treating the group as entire dataset or individual explanations for each member of the group and later aggregate them.\n",
        "\n",
        "  - Evaluation of Interpretability:\n",
        "    1. Application Level Evaluation\n",
        "    2. Human Level Evaluation\n",
        "    3. Function Level Evaluations"
      ],
      "metadata": {
        "id": "kiPGzSqncMQW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chapter 3 : Datasets"
      ],
      "metadata": {
        "id": "b1sYC4lA7IgG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chapter 4 : Interpretable Models"
      ],
      "metadata": {
        "id": "cLVJ_qq17R59"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chapter 5 : Model-Agnostic Methods"
      ],
      "metadata": {
        "id": "ch1fizCn7WQu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chapter 6 : Examples"
      ],
      "metadata": {
        "id": "BYCXCPJf7bwh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chapter 7 : Global Model-Agnostic Methods"
      ],
      "metadata": {
        "id": "ws1aAGGv7iLG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chapter 8 : Local Model-Agnostic Methods"
      ],
      "metadata": {
        "id": "vlc86aJ-7nkN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chapter 9 : Neural Network Interpretation"
      ],
      "metadata": {
        "id": "Yaqwp3xf7zwu"
      }
    }
  ]
}